{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "## Can Gözpınar 68965\n",
    "### Engr421 Hw#5"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n"
   ]
  },
  {
   "source": [
    "### Divide the data set\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in data points\n",
    "# read data into memory\n",
    "data_set = np.genfromtxt(\"hw04_data_set.csv\", delimiter = \",\")[1:,:] #remove the first x,y string\n",
    "#first 100 to training set\n",
    "trainingDataSet = data_set[:100,:] #(100,2)\n",
    "#remaining 33 to test set\n",
    "testDataSet = data_set[100:,:] #(33,2)"
   ]
  },
  {
   "source": [
    "### Decision Tree Regression Algorithm"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create necessary data structures\n",
    "node_indices = {}\n",
    "is_terminal = {}\n",
    "need_split = {}\n",
    "\n",
    "node_splits = {} #holds x values of the splits of the nodes\n",
    "node_prediction = {} #holds predicted y value for node\n",
    "\n",
    "# put all training instances into the root node\n",
    "node_indices[1] = np.array(range(len(trainingDataSet)))\n",
    "is_terminal[1] = False\n",
    "need_split[1] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initializeVaribles():\n",
    "\n",
    "    #decision tree regression algorithm\n",
    "    global node_indices\n",
    "    global is_terminal\n",
    "    global need_split\n",
    "    global node_splits\n",
    "    global node_prediction\n",
    "    global node_indices\n",
    "    global is_terminal\n",
    "    global need_split\n",
    "    # create necessary data structures\n",
    "    node_indices = {}\n",
    "    is_terminal = {}\n",
    "    need_split = {}\n",
    "\n",
    "    node_splits = {} #holds x values of the splits of the nodes\n",
    "    node_prediction = {} #holds predicted y value for node\n",
    "\n",
    "    # put all training instances into the root node\n",
    "    node_indices[1] = np.array(range(len(trainingDataSet)))\n",
    "    is_terminal[1] = False\n",
    "    need_split[1] = True"
   ]
  },
  {
   "source": [],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def trainDecisionTree(P):\n",
    "    global node_indices\n",
    "    global is_terminal\n",
    "    global need_split\n",
    "    global node_splits\n",
    "    global node_prediction\n",
    "    global node_indices\n",
    "    global is_terminal\n",
    "    global need_split\n",
    "    # learning algorithm\n",
    "    while True:\n",
    "        # find nodes that need splitting\n",
    "        split_nodes = [key for key, value in need_split.items() if value == True]\n",
    "        # check whether we reach all terminal nodes\n",
    "        if len(split_nodes) == 0:#terminate if tree is complete\n",
    "            break\n",
    "        \n",
    "        #if tree is not complete then\n",
    "        # find best split positions for all nodes\n",
    "        for split_node in split_nodes:\n",
    "            data_indices = node_indices[split_node] #elements in a given node indices\n",
    "            need_split[split_node] = False #change it since we are splitting it now\n",
    "\n",
    "            #check for current node being terminal node\n",
    "            if len(data_indices) <= P: #if less than or equal to P elements in the node then terminal \n",
    "                #calculate predicted node value gm\n",
    "                gm = np.mean(trainingDataSet[data_indices, 1])\n",
    "                #set predicted y value for the node\n",
    "                node_prediction[split_node] = gm #set prediction value for the node to gm\n",
    "\n",
    "                is_terminal[split_node] = True#pruned\n",
    "\n",
    "            else:#if not a terminal node then split further\n",
    "                is_terminal[split_node] = False\n",
    "\n",
    "                #decide on split positions\n",
    "                unique_values = np.sort(np.unique(trainingDataSet[data_indices, 0])) #sorted all x values\n",
    "                split_positions = (unique_values[1:len(unique_values)] + unique_values[0:(len(unique_values)     - 1)]) / 2 #split positions are a-b/2 between adjacent x values namely a and b\n",
    "\n",
    "\n",
    "                split_scores = np.repeat(0.0, len(split_positions))#score array for possible splits\n",
    "\n",
    "                for s in range(len(split_positions)):#iterate over each possible split index\n",
    "                        #training elements to the left of the current split\n",
    "                        left_indices = data_indices[trainingDataSet[data_indices, 0] < split_positions[s]]\n",
    "                        #training elements to the right of the current split\n",
    "                        right_indices = data_indices[trainingDataSet[data_indices, 0] >= split_positions[s]]\n",
    "\n",
    "                        #score calculation below: -->\n",
    "                        #g function is mean for left\n",
    "                        predictionLeft = np.mean(trainingDataSet[left_indices, 1])#g for left of the split\n",
    "                        predictionRight = np.mean(trainingDataSet[right_indices, 1])#g for right of the     split\n",
    "\n",
    "                        #split score is based on impurity funciton\n",
    "                        split_scores[s] = 1 / len(data_indices) * ( np.sum((np.add(trainingDataSet  [left_indices, 1], predictionLeft * -1))**2) + np.sum((np.add(trainingDataSet[right_indices, 1],  predictionRight * -1))**2) ) \n",
    "                        # <-- score calculation ends here\n",
    "\n",
    "                #choose the best split with the lowest impurity value\n",
    "                best_split = split_positions[np.argmin(split_scores)]#best split x value\n",
    "\n",
    "                #calculate predicted node value gm\n",
    "                gm = np.mean(trainingDataSet[data_indices, 1])\n",
    "\n",
    "                #set predicted y value for the node\n",
    "                node_prediction[split_node] = gm #set prediction value for the node to gm\n",
    "                node_splits[split_node] = best_split #set the split positon x for the node\n",
    "\n",
    "                 # create left node using the selected split\n",
    "                left_indices = data_indices[trainingDataSet[data_indices, 0] < best_split]\n",
    "                node_indices[2 * split_node] = left_indices # assign lower valued for d to left\n",
    "                is_terminal[2 * split_node] = False\n",
    "                need_split[2 * split_node] = True\n",
    "\n",
    "                # create right node using the selected split\n",
    "                right_indices = data_indices[trainingDataSet[data_indices, 0] >= best_split]\n",
    "                node_indices[2 * split_node + 1] = right_indices # assign higher valued for d to right\n",
    "                is_terminal[2 * split_node + 1] = False\n",
    "                need_split[2 * split_node + 1] = True\n",
    "\n",
    "                #print( \"best\",best_split,\"left:\",left_indices,\"right\",right_indices)"
   ]
  },
  {
   "source": [
    "\n",
    "### Draw test data, training data and our fit"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractTreeInfo(P):\n",
    "    #initialize variables for tree decision training first\n",
    "    initializeVaribles()\n",
    "    #call training tree decision funciton below to train\n",
    "    trainDecisionTree(P)\n",
    "    #sort the node_splits with respect to x values\n",
    "    x_dict = sorted(node_splits.items(), key=lambda x : x[1])#node_index:x_position dict with sorted x_pos\n",
    "\n",
    "    #training elements to the left of the current split\n",
    "    y_values = []#array holding y values in order for x split position\n",
    "    for i in range(len(x_dict) - 1):#add the middle y_prediction values\n",
    "        x_Pos1 = x_dict[i][1] \n",
    "        x_Pos2 = x_dict[(i + 1)][1]\n",
    "        predictionMiddle = np.mean([y for x,y in trainingDataSet if (x > x_Pos1) & (x <= x_Pos2)])\n",
    "        y_values.append(predictionMiddle)\n",
    "\n",
    "    #en sağdaki ve en soldaki eleman eksik onu da ekle son indexteki x_dict için\n",
    "    #add the leftmost prediction\n",
    "    y_values.insert(0, np.mean([y for x,y in trainingDataSet if x < x_dict[0][1]]))\n",
    "    #add the rightmost prediction\n",
    "    y_values.append(np.mean([y for x,y in trainingDataSet if x > x_dict[-1][1]]))\n",
    "\n",
    "    x_values = [x for nodeIndex, x in x_dict] #extract x values from the list\n",
    "    return x_values, y_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#run the algorithm\n",
    "P = 15\n",
    "x_values, y_values = extractTreeInfo(P)\n",
    "\n",
    "#Draw the test data, training data and our fit for P = 15 in the same figure\n",
    "#plot training data on the plot\n",
    "plt.figure(figsize = (10,6))\n",
    "\n",
    "plt.plot(trainingDataSet[:,0], trainingDataSet[:,1], \"b.\", markersize = 10, label=\"training\")#training\n",
    "plt.plot(testDataSet[:,0], testDataSet[:,1], \"r.\", markersize = 10, label=\"test\")#test set \n",
    "#plt.plot([30,40],[-50, -50], \"r\", markersize=10)\n",
    "\n",
    "#our fit, prediction\n",
    "\n",
    "\n",
    "#handle most left side\n",
    "plt.plot([0, x_values[0]], [y_values[0], y_values[0]], \"k\", markersize=10)\n",
    "#handle most right side    \n",
    "plt.plot([x_values[-1], max(trainingDataSet[:,0])], [y_values[-1], y_values[-1]], \"k\", markersize=10)  \n",
    "\n",
    "#plt.plot(x_values, y_values, \"k\", markersize=10)\n",
    "#draw the middle y_values\n",
    "for b in range(len(x_values) - 1):#draw horizontal lines\n",
    "    plt.plot([x_values[b], x_values[b + 1]], [y_values[b + 1], y_values[b + 1]], \"k\", markersize=10)   \n",
    "for b in range(len(x_values)):#draw vertical lines\n",
    "    plt.plot([x_values[b], x_values[b]], [y_values[b], y_values[b + 1]], \"k\", markersize=10)   \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.title(\"P = 15\")\n",
    "plt.legend(loc = \"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "source": [
    "### Calculate the root mean squared error (RMSE) "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRMSE(x_valuess, y_valuess):\n",
    "    #Calculate the root mean squared error (RMSE) for test data points\n",
    "    predictions = []#array holding predicted y values in order corresponding to test data set\n",
    "    for x, y in testDataSet:\n",
    "        for index in range(len(x_valuess) - 1):\n",
    "            if x < x_valuess[0]:#left most y prediction\n",
    "                predictions.append(y_valuess[0])\n",
    "                break\n",
    "            elif (x <= x_valuess[index + 1]) & (x > x_valuess[index]): #middle prediction values\n",
    "                predictions.append(y_valuess[index + 1])\n",
    "                break\n",
    "            elif x >= x_valuess[-1]:#right most y prediction\n",
    "                predictions.append(y_valuess[-1])\n",
    "                break\n",
    "\n",
    "    #apply the rmse formula\n",
    "    rmse = np.sqrt(np.sum(np.add([yTest for xTest, yTest in testDataSet], -1 * np.array(predictions))**2) / len(testDataSet) )\n",
    "    return rmse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#call rmse funciton to get the value\n",
    "rmse = getRMSE(x_values, y_values)\n",
    "print(\"RMSE is {} when P is 15\".format(rmse))"
   ]
  },
  {
   "source": [
    "### Changing Pruning parameters and plotting it"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#array holding the values of P\n",
    "p_values = range(5,55,5) #array of 5,10,15...50\n",
    "\n",
    "rmse_values = []#array to hold on rmse values for corresponding p_values value\n",
    "\n",
    "#calculate the rmse value for each p value in the array\n",
    "for p in p_values:\n",
    "    x_values, y_values = extractTreeInfo(p)\n",
    "    currentRMSE = getRMSE(x_values, y_values)\n",
    "    rmse_values.append(currentRMSE)\n",
    "    \n",
    "#x ler p_values y ler de rmse values\n",
    "plt.figure(figsize = (10,6))\n",
    "plt.plot(p_values, rmse_values, \"k\", markersize=10)#draw lines\n",
    "plt.plot(p_values, rmse_values, \"k.\", markersize=15)#draw dots    \n",
    "plt.xlabel(\"Pre-pruning size (P)\")\n",
    "plt.ylabel(\"RMSE\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}